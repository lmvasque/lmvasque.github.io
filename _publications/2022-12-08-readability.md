---
title: "A Benchmark for Neural Readability Assessment of Texts in Spanish"
collection: publications
category: conferences
permalink: /publication/2022-12-08-readability
excerpt: 'We release a new benchmark for Automated Readability Assessment (ARA) of texts in Spanish. We combined existing corpora with suitable texts collected from the Web, thus creating the largest available dataset for ARA of Spanish texts. All data was pre-processed and categorised to allow experimenting with ARA models that make predictions at two (simple and complex) or three (basic, intermediate, and advanced) readability levels, and at two text granularities (paragraphs and sentences). An analysis based on readability indices shows that our proposed datasets groupings are suitable for their designated readability level. We use our benchmark to train neural ARA models based on BERT in zero-shot, few-shot, and cross-lingual settings. Results show that either a monolingual or multilingual pre-trained model can achieve good results when fine-tuned in language-specific data. In addition, all models decrease their performance when predicting three classes instead of two, showing opportunities for the development of better ARA models for Spanish with existing resources.'
date: 2022-12-08
venue: 'In Proceedings of the Workshop on Text Simplification, Accessibility, and Readability (TSAR-2022), Abu Dhabi, United Arab Emirates (Virtual).'
slidesurl: 'https://www.youtube.com/watch?v=g-japt36HK0'
paperurl: 'https://aclanthology.org/2022.tsar-1.18/'
citation: 'Vásquez-Rodríguez, L., Cuenca-Jiménez, P., Morales-Esquivel, S., and Alva-Manchego, F. 2022. A Benchmark for Neural Readability Assessment of Texts in Spanish. In Proceedings of the Workshop on Text Simplification, Accessibility, and Readability (TSAR-2022), pages 188–198, Abu Dhabi, United Arab Emirates (Virtual). Association for Computational Linguistics.'
---
We release a new benchmark for Automated Readability Assessment (ARA) of texts in Spanish. We combined existing corpora with suitable texts collected from the Web, thus creating the largest available dataset for ARA of Spanish texts. All data was pre-processed and categorised to allow experimenting with ARA models that make predictions at two (simple and complex) or three (basic, intermediate, and advanced) readability levels, and at two text granularities (paragraphs and sentences). An analysis based on readability indices shows that our proposed datasets groupings are suitable for their designated readability level. We use our benchmark to train neural ARA models based on BERT in zero-shot, few-shot, and cross-lingual settings. Results show that either a monolingual or multilingual pre-trained model can achieve good results when fine-tuned in language-specific data. In addition, all models decrease their performance when predicting three classes instead of two, showing opportunities for the development of better ARA models for Spanish with existing resources.

[Download slides here](https://www.youtube.com/watch?v=g-japt36HK0)

[Download paper here](https://aclanthology.org/2022.tsar-1.18/)

Recommended citation: Vásquez-Rodríguez, L., Cuenca-Jiménez, P., Morales-Esquivel, S., and Alva-Manchego, F. 2022. A Benchmark for Neural Readability Assessment of Texts in Spanish. In Proceedings of the Workshop on Text Simplification, Accessibility, and Readability (TSAR-2022), pages 188–198, Abu Dhabi, United Arab Emirates (Virtual). Association for Computational Linguistics.